# 高频
## 什么是同源策略以及跨源资源共享（CORS）？
同源策略，是浏览器的一种安全机制，通过限制文档和脚本与来自另一个源的资源的交互。
从而隔离潜在的有害文档，保护用户的安全和隐私。

说白话，就是百度的前端页面无法访问搜狗的后端服务器。
> 同源指的是同协议/主机/端口相同。例如A.com的前端页面只能访问A.com的后端服务器，
若B.com的前端页面访问A.com的后端服务器，那么就有可能因为这个同源策略被拦截。

> 注意：localhost与127.0.0.1不属于同源，因为域名不同，算跨域。
> 他们的关系是通过操作系统中的hosts文件，将localhost解析为127.0.0.1，但它们算跨域。

跨源资源共享是用于在不同的源中获取资源的一种机制。解决跨域问题的方案：
* jsonp（json padding，填充式的json）：Js跨域请求ajax数据是不可以的，但是js跨域请求js脚本是可以的（不然CDN之类的就没法用了）。
`<src>、<link>、<img>`还有表单自带跨域属性，
JSONP原理就是动态插入带有跨域url（url参数有一个callback）的script标签，请求完script后，
script内的内容会调用callback函数，服务器的数据就在这callback的入参内。
缺点是只能进行get请求，容易被csrf攻击（任何网页都能构造该jsonp，防御方法跟csrf相同），优点是兼容性好（就连IE也完美支持）。
```html
<script>
function mycallback(data) {...前端的业务逻辑...}
</script>
<script src='https://xxx.com/getInfo?callback=mycallback'></script>
<!-- 上面👆标签解析后会变成如下👇，其中data是后端传过来的数据 -->
<script>mycallback(data)</script>
```
* 反向代理：nginx服务器的域名设置成为前端域名，nginx代理请求真正后端就不存在跨域问题了。
```nginx 
# nginx.config
server {
    server_name  前端域名 # 该代理nginx需要在前端域名服务器下
    location / {
        proxy_pass 后端域名 # 后端服务器可以在任意域名服务器下
    }
}
```
> 前端开发服务器也可以如此设置以避免跨域问题。
* cors：通过设置响应头信息，允许跨域请求。CORS与JSONP的使用目的相同，但是比JSONP更强大。
支持所有类型的HTTP请求，而JSONP只支持GET请求。
浏览器一旦发现AJAX请求跨源，就会自动添加一些附加的头信息（例如Origin字段），有时还会多出一次附加的请求（预检，比如说post请求会有一个预检请求）。
对于服务器来说，服务端返回响应头信息中需要返回`Access-Control-*`相关字段，这是需要后端配置的，如果响应头中没有这些信息，浏览器会拒收。
```
<!-- 一个跨域请求例子，例如A前端请求B服务器： -->
Origin: http://api.B.com
<!-- 跨域响应头中，会多出下面字段： -->
Access-Control-Allow-Origin: http://api.B.com # 该字段是必须的。它的值要么是请求时Origin字段的值，要么是一个*，表示接受任意域名的请求。
Access-Control-Allow-Credentials: true # 该字段可选。它的值是一个布尔值，表示是否允许发送Cookie。默认情况下，Cookie不包括在CORS请求之中。另一方面，开发者必须在AJAX请求中打开withCredentials属性。`xhr.withCredentials = true;`
Access-Control-Expose-Headers: FooBar # 如果想拿到相应头headers里的字段，就必须在Access-Control-Expose-Headers里面指定。这个例子指定，getResponseHeader('FooBar')可以返回FooBar字段的值。
...
```
> * Origin 由三部分组成：`scheme://host:port`，这些内容会从请求 url 中提取，其他的部分会被丢弃掉。
会在跨域请求时带上，服务端据此判断是否允许跨域，是 CORS 机制的重要一环。
> * Referer是页面url路径，在A页面跳到B页面会带上这个，用于确认请求的来源页面。例如防盗链。
> * Host 由两部分组成：host:port，Host 可以用于代理，当多个域名指向同一个 IP 时，Web Server 可以通过 Host 来识别并提供不同的服务。
例如会被nginx的server.server_name处理。
## CSRF 攻击是什么？
CSRF（Cross-site request forgery），跨站请求伪造，利用用户的登录态发起恶意请求，攻击原理：
* 用户登录受信任网站A，并在浏览器本地的A域名下生成Cookie。
* 在不登出A的情况下，访问危险网站B。
* 危险网站B向网站A的服务器发送请求，利用A的Cookie实现冒充用户对网站A进行操作。

为什么会有CSRF攻击呢？原因就在于，浏览器会依据请求的域名附带上对应域名cookie。
例如A网站有一个重要操作，接口是`A.com/some-api`，恶意网站B的页面也请求A网站的这个重要接口，
该请求会被浏览器自动带上A.com域名下的cookie，从而完成CSRF攻击。
CSRF的两个特点是通常发生在第三方域名，以及攻击者不能获取到Cookie等信息，只是使用，将cookie发送到目标网站。

解决办法就是CORS。

> 另外，跨域cookie是有作用的，一个应用是实现广告跟踪，例如a.com里一个iframe引用了google.com的广告，
那么google.com就会在google.com域名下设置广告跟踪cookie，当打开a.com时，google.com的广告就会自动加载，
从而将该广告跟踪cookie上报到google.com，从而实现广告跟踪。

## 如何实现安全的CORS，避免CSRF攻击呢？
对于跨域的简单请求（例如JSONP）（AJAX 的跨域设计就是，只要表单可以发，AJAX 就可以直接发）来说，
是必然有CSRF风险的，因为简单请求只传输一次，这时候会带上cookie发送给后端，
如果后端没有安全处理的话，就容易出问题，后端这时候可以根据请求头的origin或者referer参数拦截。
在浏览器中，JS一般会被禁止修改referer参数，因此该参数可以被认为是安全的（Forbidden Header）。

> script标签为什么能跨域？简单来说，算是一种妥协，在web早期大量使用该方式实现跨域，包括CDN，
后面有了CORS后，安全性就高多了，就一般不再用script标签实现跨域了。

如果跨域请求为非简单请求，则浏览器会先发送OPTIONS预检请求，后端服务器在接收到OPTIONS请求后，
会返回针对实际请求的要求，如果符合要求（例如该网址在白名单）的话，则可以继续发送实际请求，如果不符合的话就不会发送实际请求了。
因此针对CORS跨域请求，一般需要在服务器上配置跨域白名单（后端会根据请求头信息的Orign参数）防止恶意请求。
> 后端服务器的默认配置，例如nginx的默认配置，服务器默认是不被允许跨域的。所以跨域请求一般会被浏览器拦截，但并不意味着服务器不处理。
需要在Nginx的配置文件中配置以下参数才能成功跨域：
```
location / {  
    add_header Access-Control-Allow-Origin *;
    add_header Access-Control-Allow-Methods 'GET, POST, OPTIONS';
    add_header Access-Control-Allow-Headers 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization';

    if ($request_method = 'OPTIONS') {
        return 204;
    }
} 
```
> 跨域有两个步骤，valid_referers允许的域名
> * 第一个步骤是请求部分，浏览器向服务器发送请求信息，这时候服务器一般情况下会处理该请求，一般用来防止CSRF，
这个时候的方法要么只支持同源，要么通过valid_referers实现控制：
```
# nginx设置
valid_referers none blocked server_names 127.0.0.1 192.168.64.149 *.A.com;
if ($invalid_referer) {
    return 403;
}
```
因此防CSRF一般用referer，跨域一般用orign。
> * 第二个步骤是响应部分，服务器向浏览器发送响应信息，这时候如果服务器不在响应头添加头信息，浏览器一般会拦截该跨域请求，一般用来解决跨域。

因此，禁止跨域不一定能防止CSRF攻击，

在允许访问的情况下，这个时候后端服务器会有`Access-Control-Allow-Credentials`参数确定这个请求是否要携带cookies。
只有当允许携带的时候，并且前端发送设置`withCredentials`参数为true的时候，就有可能携带cookie了。
但这时不同的浏览器还是不一定会携带cookie，例如此时FireFox会携带，但Chrome不会。

cookie的「不认来源，只看目的」规矩在2020年开始被打破，因为80版本chrome对三方cookie的限制加强了，
还要去设置Cookie的SameSite属性，cookie的取用规则是去看请求的来源地和目的地，同源的就叫第一方cookie，例如用于用户登录的身份凭证；跨域的就叫第三方cookie。
例如广告跟踪cookie，跨网站追踪用户记录。

这种变化体现在浏览器将same-site:lax设置为默认属性。
也就是说现在cookie的取用是「既看来源，又看目的」了，之前是只要满足CORS规则，必上传cookie，现在就不一样了。
又加了一个规则，same-site是cookie的一个属性，它制约第三方cookie的携带，其值有三个none、strict、lax。

* strict代表完全禁止三方cookie，但同属一个主体运营的网站不得不重复登录。
* Lax则是折中，在某些情况下会限制三方cookie的携带，某些情况又放行，这也是浏览器的默认值（包括safari）。
* none代表完全不做限制，即之前「不认来源，只看目的」的cookie取用原则。

cookie有以下几个属性：
* domain/path：指定cookie使用时，可以被携带到哪些域名或合法域名的哪些URI。
* expire/max-age: 指定cookie的有效期，其中expire是一个绝对时间，max-age是相对时间
* secure：只能在HTTPS环境中被下发以及携带
* http-only：禁止客户端脚本通过 document.cookie 获取 cookie，避免 XSS 攻击

SameSite Lax 仅在顶部窗口导航（例如`<a>`标签、window.open()）中的GET请求中发送 cookie 。
可以这么理解，浏览器将same-site的默认值从none调整到了lax（safari直接为strict），
其实这个参数主要用于cookie的默认限制，
这样，假如后端忘记（或者错误）配置跨域参数，导致服务器暴露在csrf攻击下，但是由于浏览器改了cookie的默认same-site,
cookie默认不上传，这样就极大增加了安全性，毕竟服务器配置跨域错误不算少数。

但Cookie 机制并未遵循严格的同源策略，允许一个子域可以设置或获取其父域的 Cookie。
只要协议相同，并且有效顶级域名+二级域名相同即可，不用考虑端口号（可以理解为跨站，跨站一定跨域，跨域不一定跨站）。

> 为什么cookies也不受同源策略限制？主要也是历史原因，因为 cookies 在同源策略之前的广泛使用了，直接限制会有兼容性问题，
所以后来有了更灵活的 Content-Security-Policy，网站可以自己定制需要的策略。
正常情况下，同一个一级域名下的两个二级域名也不能交互使用Cookie，因为二者的域名并不严格相同。
Cookie的作用域仅仅由domain和path决定，与协议和端口无关。

如果连域名都不同该怎么办呢？cookie还有一个属性same-party可以把例如.taobao.com、.tmall.com和.alimama.com三个站合起来，
当作一个站，它们设置的cookie在这个集合内部不会被当作第三方cookie对待。
需要注意的是，使用same-party属性时，必须要同时使用https(secure属性)，并且same-site不能是strict。

总结：一般而言，普通的业务需求，如果没有跨域需求，或者跨域的话不用cookie，
就直接全部禁止跨域或者跨域禁止携带cookie就行了，例如设置Cookie Samesite属性为Strict。

如果真的需要跨域且需要携带cookie，那么首先，不用简单请求，
然后，设定好服务器的白名单，确定跨域的域名有几个，其他的禁止，就可以了。
白名单可以是服务器的referer白名单配置，或者cookie的same-party属性配置。

如果服务器不太好配置跨域白名单（例如前端可能由其他人提供），而且需要cookie能力，可以有以下方法
（大致就是关键信息不能存在cookie）：

* 可以在服务器生成一个token，存在服务器session里，下发在前端的dom中。
请求的时候携带在请求参数里，这样第三方恶意网站就获取不到这个token了。

* 或者使用双重Cookie，再加一个‘scrfcookie’，发送时，传到参数上，
由于第三方恶意网站是获取不到cookie的内容的，因此可以防CSRF攻击。

## XSS 攻击是什么？
* Cross Site Script，跨站脚本攻击。是指攻击者在网站上注入恶意script代码，
通过恶意脚本对客户端网页进行篡改，从而在用户浏览网页时，对用户浏览器进行控制或者获取用户隐私数据的一种攻击方式。
比如攻击者在社区或论坛上写下一篇包含恶意 JavaScript 代码的文章或评论，文章或评论发表后，所有访问该文章或评论的用户，
都有可能在他们的浏览器中执行这段恶意的 JavaScript 代码。

XSS攻击分为：
* 反射式，例如php
* 存储式
* dom式，例如js
```php
<a href="$var">test</a>
<a href="" onclick=alert(1) \">test</a>
```

## 如何防范XSS攻击？*
对输入(和URL参数)进行过滤，对输出进行编码。
* 对提交的所有内容进行过滤，对url中的参数进行过滤，过滤掉会导致脚本执行的相关内容，例如过滤掉`<script>`标签；
* 对动态输出到页面的内容进行html编码，使脚本无法在浏览器中执行，例如半角字符直接替换成全角字符，转义特殊字符。

## 如何减少预检请求？
* 预检缓存。
* 使用websocket。
* 使用简单请求。

## 强制缓存和协商缓存有什么区别？
* 强制缓存：根据响应头里的过期时间Expires判断，当浏览器再次加载资源时，如果在这个过期时间内，则命中强缓存并返回，
并不会向服务端发起请求，记录为200状态。
* 协商缓存：客户端向服务端发送请求进行协商判断，当浏览器再次加载资源时，如果资源没有变化则继续使用本地缓存，记录为304状态；
如果资源发生变化，服务端响应数据，记录为200状态。

> 浏览器缓存(Brower Caching)是浏览器将用户最近请求过的文档存储在本地磁盘里，当访问者再次访问时，浏览器就可以直接从本地磁盘加载文档。

## 如何清除缓存，强制刷新？
* 在服务器上加缓存清除的字段，即`Cache-Control no-store;`字段。
* 在前端页面可以加`<META HTTP-EQUIV="Cache-Control" CONTENT="no-cache, must-revalidate"> `标签。
* 在url上加随机字符串。

## get/post 请求的区别？
* 在语义上，get请求用于获取数据，是幂等的，多次相同的GET请求不能对服务器的状态有影响，因此get请求可以被缓存以提高性能；
post请求用于提交数据，不是幂等的，会对服务器状态产生影响，不能缓存。
* 在参数上，get传参通过地址URL传递，只支持ASCII字符，只能URL编码，长度最多2KB左右；
post将参数存放在HTTP的包体内，没有字符类型限制，有多种编码格式，长度最多在10MB左右。

## Cookie、localStorage、sessionStorage、IndexedDB的区别？
* Cookie有过期时间，Cookie的信息会在http请求的时候携带到服务器。
* sessionStorage是会话存储，浏览器关闭就会消失。
* localStorage是永久存储，最大限制一般为5-10MB，所有数据都将作为字符串存储。
* IndexedDB是前端数据库，能存储几百MB的数据，api比较复杂。

## 如何优化页面加载时间？*
* React的懒加载
* 图片的懒加载库
* 合并/简化后端接口
* 接口数据的缓存

其实问题一个就是后端接口太慢，第二个是图片加载太慢

## TCP与UDP是什么？
* UDP是一种无连接的，不可靠的，基于报文的传输层通信协议，能够多播广播。
* TCP是一种面向连接的、可靠的、基于字节流的传输层通信协议，使用三次握手协议建立连接、四次挥手断开连接。
    * 三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的：
        * 第一次握手（客户端发送 SYN 报文给服务器，服务器接收该报文）：客户端什么都不能确认；服务器确认了对方发送正常，自己接收正常
        * 第二次握手（服务器响应 SYN 报文给客户端，客户端接收该报文）：客户端确认了：自己发送、接收正常，对方发送、接收正常；服务器确认了：对方发送正常，自己接收正常
        * 第三次握手（客户端发送 ACK 报文给服务器）：客户端确认了：自己发送、接收正常，对方发送、接收正常；服务器确认了：自己发送、接收正常，对方发送、接收正常
    > 服务器收到客户端第一次握手信息之后，此时双方还没有完全建立其连接，服务器会把这种状态下的请求连接放在一个队列里，我们把这种队列称之为半连接队列。同样，在关闭时，
        TCP 提供了连接的一端在结束它的发送后还能接收来自另一端数据的能力，这叫半关闭特性。
    * 终止一个 TCP 连接要经过四次挥手。这是由于 TCP 的半关闭（half-close）特性造成的，因此需要同时关闭客户端和服务端，双方都应该知道对方已关闭，客户端或服务端均可主动发起挥手动作。例如客户端先发起的关闭请求：
        * 第一次挥手客户端发送给服务端一个信息，客户端关闭TCP链接，但并不知道服务端关闭，因此处于等待状态1。
        * 第二次挥手服务端发送给客户端一个信息，客户端接受到后知道服务端已经知道自己打算关闭了，于是客户端到服务端的连接释放，客户端处于等待状态2，此时的 TCP 处于半关闭状态，服务端仍可发送数据到客户端。
        * 第三次挥手服务端发送给客户端一个信息，表示服务端也想关闭连接，此时服务端处于一种等待状态，客户端接收到后处于等待状态3。
        * 第四次挥手客户端发送给服务端一个信息，服务端收到后关闭连接。

## UserAgent是什么？
UserAgent，简称UA，是一个使服务器能够识别用户使用的浏览器类型、版本以及运行浏览器的操作系统等信息的字符串。
它作为浏览器请求头部信息的一部分发送给服务器，以便服务器可以返回合适格式和版本的内容。
```js
Chrome User Agent
Windows电脑上，Chrome浏览器的UA：
Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36
Firefox User Agent
Windows电脑上，Firefox浏览器的UA：
Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:125.0) Gecko/20100101 Firefox/125.0
Safari User Agent
Mac电脑上，Safari浏览器的UA：
Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15
Android User Agent
Android手机上，Chrome浏览器的UA：
Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Mobile Safari/537.36
iOS User Agent
iPhone手机上，Safari浏览器的UA：
Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/604.1
```

# 低频

## 什么是URL编码？

Url编码通常也称为百分号编码，通过使用%百分号加上该字节的十六进制组成编码。
因为URL中有些字符会引起歧义，例如URL参数字符串中如果包含”&”或者”%”就会造成服务器解析错误，因此就需要对其进行编码。

encodeURI用于将字符串作为 URI 进行编码。其目的是对目标URI进行编码使之成为一个合格的URI。

encodeURIComponent用于将字符串作为URI参数进行编码。因此encodeURIComponent还必须转义用于分隔URI各个部分的标点符号，以防止歧义。

>Url编码默认使用的字符集是US-ASCII[ˈæski]。对于Unicode字符，则使用%百分号加上该字节的utf-8字节组成编码。

标准的Base64并不适合直接放在URL里传输，因为URL编码器会把标准Base64中的“/”和“+”字符变为形如“%XX”的形式，而这些“%”号在存入数据库时还需要再进行转换，因为ANSI SQL中已将“%”号用作通配符。

为解决此问题，可采用一种用于URL的改进Base64编码，它在末尾填充'='号，并将标准Base64中的“+”和“/”分别改成了“-”和“_”，这样就免去了在URL编解码和数据库存储时所要作的转换，避免了编码信息长度在此过程中的增加，并统一了数据库、表单等处对象标识符的格式。

## 讲一讲https以及证书（SSL）
* https是密文传输，通过非对称密钥，数字证书等方式完成数据加密传输。解决了http明文传输易受到中间人攻击的问题。
* 非对称加密是指一对不同的密钥，用其中一个密钥加密的密文，只能被另一个密钥解开，公开的密钥称为公钥，不公开的称为私钥。
能解决对称加密被中间人获取到密钥的问题，但仍不能解决中间人在中间代理信息的问题，即中间人获取到公钥后，对两端用自己的公钥私钥代理信息。
* 证书则能解决中间人代理信息的问题
    1. 首先服务端使用摘要算法（例如MD5）将证书明文（例如域名，服务端公钥）生成摘要，然后送给CA权威机构。
    2. CA机构将摘要用CA机构自己的私钥进行加密，得出来的叫签名，然后附在证书上。
    3. 证书被发送到客户端，客户端通过同样的摘要算法对证书明文计算摘要，然后用CA机构的公钥解开签名得到解密的摘要，
两者比对相同，则证明证书没有篡改，证书上服务端的公钥是该服务端生成的公钥，因此客户端拿到了服务端的公钥。
* 浏览器向服务器发起Https请求的流程如下：
    1. 首先浏览器向服务器发起请求。
    2. 服务器将证书机构颁发给自己的证书传递给浏览器。
    3. 浏览器从本地安装的根证书中找到证书机构的公钥，用公钥来验签证书的正确性，确保是证书机构用私钥签名的合法证书，从而拿到了服务器公钥。
    4. 浏览器随机生成一个对称秘钥key，用证书中的服务器公钥加密这个key，再传输给服务器。
    5. 服务器用私钥解密后取出对称秘钥key，并用该key加密确认内容返回给客户端，告知可以开始通信。
    6. 浏览器与服务器开始采用该key进行加密通信。
## http的状态码说几个？
> 1xx(临时响应)2xx(请求成功)3xx(重定向)4xx(请求错误)5xx(服务器错误)

* 100：请求者应当继续提出请求。
* 101：切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到 HTTP 的新版本协议。
* 200：正确的请求返回正确的结果。
* 201：表示资源被正确的创建。比如说，我们 POST 用户名、密码正确创建了一个用户就可以返回 201。
* 202：请求是正确的，但是结果正在处理中。这时候客户端可以通过轮询等机制继续请求。
* 300：请求成功，但结果有多种选择。相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择。
* 301：请求成功，但是资源被永久转移。返回信息会包括新的 URI，浏览器会自动定向到新 URI。今后任何新的请求都应使用新的 URI 代替。
* 304：请求的资源并没有被修改过。服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源。
* 400：请求出现错误，比如请求头不对等。
* 401：没有提供认证信息。请求的时候没有带上 Token 等。
* 402：为以后需要所保留的状态码。保留，将来使用。
* 403：请求的资源不允许访问。就是说没有权限。
* 404：请求的内容不存在。
* 500：服务器错误。
* 501：请求还没有被实现。服务器不支持请求的功能，无法完成请求。

## 什么是防盗链机制？*
防盗链技术用于防止网站资源被未经授权的第三方网站引用，导致原网站的带宽资源被过度消耗。

防盗链通常通过检查HTTP请求的Referer头部来实现。
如果Referer头部显示请求来自未经授权的网站，服务器可以拒绝请求。

* Web服务器配置：Web服务器如Apache、Nginx等，都支持通过配置文件实现防盗链设置。
* 使用CDN服务：一些内容分发网络（CDN）提供商提供了防盗链功能。

## CDN是什么？*
CDN即内容分发网络。是一组分布在不同地理位置的服务器，其目的是更有效地向用户分发互联网内容。
通过缓存资源在多个服务器上，并根据每个用户的地理位置将请求路由至最近的服务器。
CDN可以显著减少延迟，加快加载速度，并提高网站的安全性和可靠性。

## etag是什么？*
Etag 是URL的Entity Tag，用于标示URL对象是否改变，区分不同语言和Session等等。
具体内部含义是使服务器控制的，就像Cookie那样。

ETag 是“实体标签”（Entity Tag）的缩写，是资源的一个唯一标识，主要是用来解决修改时间无法准确区分文件变化的问题。

一般是一个文件的哈希值，用于缓存。

HTTP中并没有指定如何生成ETag，哈希是比较理想的选择。

浏览器请求获得文件后，服务器返回该文件的最后修改时间Last-Modified。
某些文件修改非常频繁,比如在秒以下的时间内进行修改(比方说 1s 内修改了 N 次),If-Modified-Since能检查到的粒度时 s 级的,这种修改无法判断(或者说 UNIX 记录 MTIME只能精确到秒)

## 如何大文件分片上传？*

## websock知道多少？*

## 如何优化图片加载？
* 压缩图片
* 使用响应式图片
* 图片懒加载
* CDN加速
## 简述前端性能优化？*
页面内容方面
* 通过文件合并、css 雪碧图、使用 base64 等方式来减少 HTTP 请求数，避免过多的请求造成等待的情况；
* 通过 DNS 缓存等机制来减少 DNS 的查询次数；
* 通过设置缓存策略，对常用不变的资源进行缓存；
* 通过延迟加载的方式，来减少页面首屏加载时需要请求的资源，延迟加载的资源当用户需要访问时，再去请求加载；
* 通过用户行为，对某些资源使用预加载的方式，来提高用户需要访问资源时的响应速度；
服务器方面
* 使用 CDN 服务，来提高用户对于资源请求时的响应速度；
* 服务器端自用 Gzip、Deflate 等方式对于传输的资源进行压缩，减少传输文件的体积；
* 尽可能减小 cookie 的大小，并且通过将静态资源分配到其他域名下，来避免对静态资源请求时携带不必要的 cookie；

## 什么是http2？http2比http1好在哪里？
1. HTTP/1.0，每一个TCP连接只能发送⼀个HTTP请求，完事了就关闭，下⼀个HTTP请求将再次建⽴TCP连接。
2. HTTP/1.1，默认采⽤持续连接，即默认Connection: keep-alive，TCP连接默认不关闭，可以被多个HTTP请求复⽤。
同时增加了管道机制，在同⼀个TCP连接⾥，允许多个请求同时发送，增加了并发性，进⼀步改善了HTTP协议的效率，
但是同⼀个TCP连接⾥，所有的数据通信是按次序进⾏的。回应慢，会有许多请求排队，造成”队头堵塞”。
3. HTTP/2.0，加了双⼯模式，即不仅客户端能够同时发送多个请求，服务端也能同时处理多个请求，解决了队头堵塞的问题。
使⽤了多路复⽤的技术，做到同⼀个连接并发处理多个请求，⽽且并发请求的数量⽐HTTP1.1多了好⼏个数量级。
HTTP2虽然只有一条TCP连接，但是在逻辑上分成了很多stream。HTTP2把要传输的信息分割成一个个二进制帧，不同的请求或者响应帧可以互相穿插。

* 二进制分帧，HTTP/2采用二进制格式传输数据，而非HTTP1.X的文本格式，二进制协议解析起来更高效。
* 头部压缩，一般而言，消息主体都会经过gzip压缩，或者本身传输的就是压缩过后的二进制文件，但状态行和头部却没有经过任何压缩，直接以纯文本传输。
HTTP2.0使用HPACK算法对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。
* 服务器推送，服务器端可以在发送页面HTML时主动推送其他资源，而不用等到浏览器解析到相应位置，发起请求在响应。
例如服务端可以主动把js和css文件推送给客户端，而不需要客户端解析HTML时再发送这些请求。

## HTTP/1.1⻓连接和HTTP/2.0多路复⽤的区别?
* HTTP/1.1：同⼀时间⼀个TCP连接只能处理⼀个请求, 采⽤⼀问⼀答的形式, 上⼀个请求响应后才能处理下⼀个请求. 
            由于浏览器最⼤TCP连接数的限制, 所以有了最⼤并发请求数的限制。
* HTTP/2.0：同域名下所有通信都在单个连接上完成，消除了因多个 TCP 连接⽽带来的延时和内存消耗。
            单个连接上可以并⾏交错的请求和响应，之间互不⼲扰。

但现实很残酷，为什么很多业务用了 HTTP/2，反倒不如 HTTP1.1 呢？

第一：HTTP/2 解决了 HTTP 协议层面的队头阻塞，但是 TCP 的队头阻塞仍然没有解决，所有的流都在一条 TCP 连接上，
如果万一序号小的某个包丢了，那么 TCP 为了保证到达的有序性，必须等这个包到达后才能滑动窗口，
即使后面的序号大的包已经到达了也不能被应用程序读取。这就导致了在多条流并发的时候，某条流的某个包丢了，
序号在该包后面的其他流的数据都不能被应用程序读取。这种情况下如果换做 HTTP1.1，由于 HTTP1.1 是多条连接，
某个连接上的请求丢包了，并不影响其他连接。所以在丢包比较严重的情况下，HTTP/2 整体效果大概率不如 HTTP1.1

第二：多流并发带来了请求优先级的问题，因为有的请求客户端（比如浏览器）希望它能尽快返回，有的请求可以晚点返回；
又或者有的请求需要依赖别的请求的资源来展示。流的优先级表示了这个请求被处理的优先级，
比如客户端请求的关键的 CSS 和 JS 资源是必须高优先级返回的，图片视频等资源可以晚一点响应。
流的优先级的设置是一个难以平衡或者难以做到公平合理的事情，如果设置稍微不恰当，就会导致有些请求很慢，
这在用户看来，就是用了 HTTP/2 之后，怎么有的请求变慢了。

## QUIC协议是什么？
QUIC 全称：Quick UDP Internet Connections，是一种基于 UDP 的传输层协议。
由 Google 自研，2012 年部署上线，2013 年提交 IETF，2021 年 5 月，IETF 推出标准版 RFC9000。

QUIC = HTTP/2 + TLS + UDP

如果有一个协议能让你的上网速度，在不需要任何修改的情况下就能提升 20%，特别是网络差的环境下能够提升 30% 以上；
如果有一个协议可以让你在 WiFi 和蜂窝数据切换时，网络完全不断开、直播不卡顿、视频不缓冲；你愿意去了解一下它吗？它就是 QUIC 协议。

HTTP/3 是第三个主要版本的 HTTP 协议。与其前任 HTTP/1.1 和 HTTP/2 不同，在 HTTP/3 中，弃用 TCP 协议，
改为使用基于 UDP 协议的 QUIC 协议实现。所以，HTTP/3 的核心在于 QUIC 协议。
显然，HTTP/3 属于应用层协议，而它使用的 QUIC 协议属于传输层协议

QUIC 协议的优秀特性：
* 建连快，初次建连只需要 1 个 RTT 即可完成建连。后续再次建连就可以使用 0-RTT 特性，
整个握手过程需要 2 次握手（第三次握手是带了数据的），所以整个握手过程只需要 1-RTT（RTT 是指数据包在网络上的一个来回）的时间。
* 多路复用：QUIC升华了HTTP/2中的多路复用技术，实现了基于互相独立的多流（多通道）数据传输，从根本上解决了TCP存在的队头阻塞问题。
* 内生安全：TCP报文的整个头部是通过明文进行传输的，且如果需要在建立TCP连接过程中需要额外进行TLS握手，
而对QUIC来说，除了例如目的ID等个别字段外，报文头部中的大部分字段也进行了加密；

* 网络质量较好的链路上QUIC的表现可能还不如TCP：这一点早在2017年的SIGCOMM会议上，从谷歌发表的论文中就可以看出来[1]，
其中特别提到在高带宽（超过100Mbps）、低时延（几毫秒）和低丢包率的网络中，QUIC的性能有时还不如TCP。另外在2020年的SIGCOMM会议上，
谷歌专门针对QUIC的CPU使用率情况做了相关汇报[2]：2017年所做的实验可以表明，同等流量下，（2017年的）QUIC的CPU消耗是TCP/SSL的2倍左右，
即使后续进行了一些优化，但是仍然要高于使用了SSL的TCP。

从公开的数据来看，国内各个厂（腾讯、阿里、字节、华为、OPPO、网易等等）使用了 QUIC 协议后，都有很大的提升，
比如网易上了 QUIC 后，响应速度提升 45%，请求错误率降低 50%；比如字节火山引擎使用 QUIC 后，建连耗时降低 20%~30%；
比如腾讯使用 QUIC 后，在腾讯会议、直播、游戏等场景耗时也降低 30%；


## 什么是Jwt鉴权机制？
JSON Web Token（缩写 JWT）是目前最流行的跨域认证解决方案，本质就是一个字符串书写规范，作用是用来在用户和服务器之间传递安全可靠的信息。
在目前前后端分离的开发过程中，使用token鉴权机制用于身份验证是最常见的方案，流程如下：
* 服务器当验证用户账号和密码正确的时候，给用户颁发一个令牌，这个令牌作为后续用户访问一些接口的凭证
* 后续访问会根据这个令牌判断用户时候有权限进行访问，每个后续请求都将包含 JWT
相对于session/cookie机制，没有跨域问题，不占用额外空间存储多余信息，适合分布式系统

Token，分成了三部分，头部（Header）、载荷（Payload）、签名（Signature）
签名是对头部和载荷内容进行签名，一旦前面两部分数据被篡改，只要服务器加密用的密钥没有泄露，得到的签名肯定和之前的签名不一致


## 什么是单点登录，如何实现？
单点登录的英文名叫做：Single Sign On（简称SSO），指在同一帐号平台下的多个应用系统中，用户只需登录一次，即可访问所有相互信任的系统。简而言之，多个系统，统一登陆。

sso需要一个独立的认证中心，所有子系统都通过认证中心的登录入口进行登录，登录时带上自己的地址，子系统只接受认证中心的授权，授权通过令牌（token）实现，sso认证中心验证用户的用户名密码正确，创建全局会话和token，token作为参数发送给各个子系统，子系统拿到token，即得到了授权，可以借此创建局部会话，局部会话登录方式与单系统的登录方式相同。

单点登录的实现方案，一般就包含：Cookies，Session同步，分布式Session，目前的网站采用比较多的方式是token令牌和分布式Session的方式。

## 进程和线程的区别？
* 进程是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配的基本单位。每个进程都有独立的地址空间和资源，包括内存、文件句柄等，系统在运行时会为每个进程分配资源。
* 线程是操作系统能够进行运算调度的最小单位，是进程中的一个执行流程。线程共享所属进程的地址空间和资源，没有自己独立的地址空间。线程所使用的资源来自其所属进程的资源。

## 介绍下304过程？
304码是读取缓存
* 浏览器请求资源时首先尝试强制缓存，命中资源的Expires 和 Cache-Control，其中Cache-Control优先级比Expires高。
> Expires 和 Cache-Control都用于缓存时间设置，Cache-Control: max-age=30表示客户端将这个缓存最多保存30秒，
浏览器请求时发现是相同的URL才使用缓存，那么可以设置查询参数来保证URL的不同。Expires 是以前用来控制缓存的http头，现在首选 Cache-Control。
Expires 响应头包含日期/时间， 即在此时候之后，响应过期。因为过期标准的时间用的是本地时间，所以不靠谱。
总的来说，Cache-Control设置时间长度，Expires 设置时间点。
* 强缓存失效，进入协商缓存阶段，控制协商缓存的字段分别有：Last-Modified / If-Modified-Since 和 Etag / If-None-Match，用于记录页面的最后修改时间。
其中Etag / If-None-Match的优先级比Last-Modified / If-Modified-Since高，所以会先判断ETag。
> Last-Modified 是由服务器发送给客户端的HTTP请求头标签，是一个时间戳，即服务器存储的文件修改时间；
> * If-Modified-Since 则是由客户端发送给服务器的HTTP请求头标签，客户端第二次请求此URL时，浏览器会向服务器传送 If-Modified-Since 报头，询问该时间之后文件是否有被修改过，
> 发送的时间就是Last-Modified的时间，如果服务器端的资源没有变化，则时间一致，自动返回HTTP状态码304（Not Changed.）状态码，内容为空，这样就节省了传输数据量。
> * ETag是HTTP1.1中才加入的一个属性，用来帮助服务器控制Web端的缓存验证。与Last-Modified用法大致相同，但是用的是文件哈希，所以比时间更准确一点。

## 粘包问题分析与对策？
TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。
例如“我是小猫”，“我是小狗”两个TCP包变成了“我是小猫我”，“是小狗”两个包，第一个包就粘包了。
简单得说，在流传输中出现，UDP不会出现粘包，因为它有消息边界。

粘包情况有两种，一种是粘在一起的包都是完整的数据包，另一种情况是粘在一起的包有不完整的包。

为了避免粘包现象，可采取以下几种措施：
* 对于发送方引起的粘包现象，用户可通过编程设置来避免，TCP提供了强制数据立即传送的操作指令push，
TCP软件收到该操作指令后，就立即将本段数据发送出去，而不必等待发送缓冲区满（否则会一直等待缓冲区满再发送，这就是粘包的原因：Nagle 算法）；
* 对于接收方引起的粘包，例如数据放在缓冲区未及时取走，多个数据放一起就粘包了。可以加入头尾标志，加入消息长度信息。
