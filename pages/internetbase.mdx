# 高频
## 什么是同源策略以及跨源资源共享（CORS）？
同源策略，是浏览器的一种安全机制，通过限制文档和脚本与来自另一个源的资源的交互。
从而隔离潜在的有害文档，保护用户的安全和隐私。

跨源资源共享是用于在不同的源中获取资源的一种机制。解决跨域问题的方案：
* jsonp（json+padding，填充式的json）：Js跨域请求ajax数据是不可以的，但是js跨域请求js脚本是可以的。
`<src><link><img>`自带跨域属性，
JSONP原理就是动态插入带有跨域url的script标签，执行完script后，会调用callback函数，
参数就是获取到的数据（而Ajax是页面无刷新请求数据操作）。
缺点是只能进行get请求，容易被劫持（类似csrf），优点是兼容性好。
* nginx反向代理：利用nginx把跨域反向代理为不跨域，将`server.server_name`设置为前端网址，
在`server.location`里设置`proxy_pass 后端网址`，这样就不存在跨域了。
* cors：通过设置响应头信息，允许跨域请求。但会产生额外的请求(预检)，
浏览器一旦发现AJAX请求跨源，就会自动添加一些附加的头信息，有时还会多出一次附加的请求（预检），
服务端返回头信息中需要返回`Access-Control-*`相关字段，这是需要后端配置的。

## XSS 攻击是什么？
* Cross Site Script，跨站脚本攻击。是指攻击者在网站上注入恶意script代码，
通过恶意脚本对客户端网页进行篡改，从而在用户浏览网页时，对用户浏览器进行控制或者获取用户隐私数据的一种攻击方式。
比如攻击者在社区或论坛上写下一篇包含恶意 JavaScript 代码的文章或评论，文章或评论发表后，所有访问该文章或评论的用户，
都有可能在他们的浏览器中执行这段恶意的 JavaScript 代码。

XSS攻击分为：
* 反射式，例如php
* 存储式
* dom式，例如js
```php
<a href="$var">test</a>
<a href="" onclick=alert(1) \">test</a>
```

## 如何防范XSS攻击？*
对输入(和URL参数)进行过滤，对输出进行编码。
* 对提交的所有内容进行过滤，对url中的参数进行过滤，过滤掉会导致脚本执行的相关内容，例如过滤掉`<script>`标签；
* 对动态输出到页面的内容进行html编码，使脚本无法在浏览器中执行，例如半角字符直接替换成全角字符，转义特殊字符。

## CSRF 攻击是什么？
CSRF（Cross-site request forgery），跨站请求伪造，利用用户的登录态发起恶意请求，攻击原理：
* 用户登录受信任网站A，并在本地生成Cookie。
* 在不登出A的情况下，访问危险网站B。
* 危险网站B向网站A发送请求，利用A的Cookie实现冒充用户对网站A进行操作。

原因就在于，浏览器会依据加载的域名附带上对应域名cookie。而script、image、iframe的src都不受同源策略的影响。
所以我们可以借助这一特点，实现跨域，在B网站可以去调用A网站的接口。因此get请求相对而言会比较危险。
而post的话，就容易被后端设置的跨域限制拦截，



script标签为什么能跨域？
因为这个脚本是由A主机的HTML文件的嵌入的script标签发起请求获取的，因此这个脚本的来源是属于A主机的。
jsonp的script标签请求回来的资源与当前域是相同的域，因此不受同源策略的影响。

cookies 不受同源策略限制，主要是历史原因，因为 cookies 在同源策略之前的广泛使用了，直接限制会有兼容性问题，
所以后来有了更灵活的 Content-Security-Policy，网站可以自己定制需要的策略。

例如我在 a.com 设了 cookies A=1，然后引用一个 b.com 的图片，那 b.com 的服务端能获取到 A 这个 cookies 吗？

答：不行的，因为 cookies 是分域名发送的，浏览器请求 b.com 的图片时是不会把 a.com 的 cookies 发到 b.com 的服务端。

但是 b.com 自己设的 B=2，b.com 的服务端是可以获取到的（就是这样实现了广告跟踪）。


从A1网页跳转到A2网页的时候，浏览器会自动携带cookie过去【因为同域】。
而如果是从A网页跳转到B网页的话，由于不同域，此时是不会携带cookie过去的。
正常情况下，同一个一级域名下的两个二级域名也不能交互使用Cookie，因为二者的域名并不严格相同。

那这就有一个问题，在B.com前端网页上请求A.com的后端接口，会带上A.com前端网页的cookie吗？会带上B.com前端网页的cookie吗？
* 会带上A.com前端网页的cookie，不然csrf攻击就不存在了
* 可能会带上B.com前端网页的cookie，这是一个标准的跨域请求，可以在请求上带上B.com前端网页的cookie，这需要
后端服务器会有`Access-Control-Allow-Credentials`参数为true，前端发送设置`withCredentials`参数为true，
并且cookie的`SameSite`属性为`None`，才能实现跨域cookie传递。如果想所有二级域名都可以使用该Cookie，需要设置Cookie的domain参数为一级域名。

那么又出现一个问题，A.com的前端实际上在C.com，通过跨域请求A.com的后端接口，此时B.com前端网页请求A.com的后端接口，会带上C.com前端网页的cookie吗？
* 肯定不会带上C.com前端网页的cookie，那这就解决csrf攻击了。

那么又出现一个问题，B.com前端网页请求B.com后端接口产生了cookie，B.com前端网页请求A.com后端接口，能带上B.com后端接口产生的cookie吗？
* 这个，额。。。。




Cookie的作用域仅仅由domain和path决定，与协议和端口无关。

CSRF的两个特点是通常发生在第三方域名，以及攻击者不能获取到Cookie等信息，只是使用。

在满足简单请求的情况下，浏览器会自动携带Cookie发送跨域请求，因为简单请求只请求一次，这时候不带就没机会带了。
也就是说进行身份校验的会话凭证如果存储在Cookie中，并且Web应用中的一些很重要的操作是用简单请求的方式完成，
那么就很容易遭受CSRF攻击。

如果跨域请求为非简单请求，则浏览器会先发送OPTIONS预检请求，后端服务器在接收到OPTIONS请求后，
会返回针对实际请求的要求，如果符合要求的话，则会继续发送实际请求，如果不符合的话就不会发送实际请求了。
这个时候后端服务器会有`Access-Control-Allow-Credentials`参数确定这个请求是否要携带cookies。
只有当允许携带的时候，并且前端发送设置`withCredentials`参数为true的时候，就有可能携带cookie了。
但不同的浏览器不一定会携带cookie，例如此时FireFox会携带，但Chrome不会。
因为80版本chrome对三方cookie的限制加强了，还要去设置Cookie的SameSite属性，这又引出一个三方cookie的概念：

例如第一方cookie就是用户登录的身份凭证cookie，而第三方Cookie主要用于跨网站追踪用户记录，
* domain 指定cookie未来使用时，可以被携带到哪些域名。
* path：指定cookie未来使用时，可以被携带到合法域名的哪些URI。
* expire/max-age: 指定cookie的有效期，其中expire是一个绝对时间，max-age是相对时间
* secure：只能在HTTPS环境中被下发以及携带
* http-only：禁止客户端脚本通过 document.cookie 获取 cookie，避免 XSS 攻击。

cookie的取用规则是去看请求的目的地，同源的就叫第一方cookie，跨域的就叫第三方cookie。
「不认来源，只看目的」规矩在2020年开始被打破，这种变化体现在浏览器将same-site:lax设置为默认属性。
也就是说现在cookie的取用是「既看来源，又看目的」了。
same-site是cookie的一个属性，它制约第三方cookie的携带，其值有三个none、strict、lax。
* strict代表完全禁止三方cookie，但同属一个主体运营的网站不得不重复登录。
* Lax则是折中，在某些情况下会限制三方cookie的携带，某些情况又放行，这也是浏览器的默认值（包括safari）。
* none代表完全不做限制，即之前「不认来源，只看目的」的cookie取用原则。

可以这么理解，浏览器将same-site的默认值从none调整到了lax，
SameSite Lax 仅在顶部窗口导航（例如`<a>`标签、window.open()）中的GET请求中发送 cookie 。

比如说现在同源前后端，第三方发一个请求，带上了同源前端的cookie，这是三方cookie，可以被samesite隔离。
但是现在前端放在CDN的域名，第三方发一个请求，后端的域名在前端是没有cookie的，因此不存在带cookie的情况。
即便用户点击了csrf链接，浏览器也找不到同域名的cookie，因为前端cookie放到了cdn域名下，而请求后端是后端的服务器域名。
不对，跟cdn无关，cdn只是域名代理了一下。

如果前后端域名不同，那么还有csrf攻击吗？
跨域的话，携带的是谁的cookie？A跨域访问B，带上A域和B域的cookie？
高版本浏览器只能是让服务端手动设置 SameSite=None；
请求哪个域名，携带哪个域名的cookie？当然不是。

比如 A：静态网站
B：后端服务器
C：攻击网站

如果A=B，C请求B，这时候带C的cookie，还是A的cookie？
如果A!=B，C请求B，这时候带C的cookie，还是A的cookie？








Cookie 机制并未遵循严格的同源策略，允许一个子域可以设置或获取其父域的 Cookie。

HTTPOnly 的应用仍存在局限性，一些浏览器可以阻止客户端脚本对 Cookie 的读操作，但允许写操作；
此外大多数浏览器仍允许通过 XMLHTTP 对象读取 HTTP 响应中的 Set-Cookie 头。

same-party可以把.taobao.com、.tmall.com和.alimama.com三个站合起来，
它们设置的cookie在这个集合内部不会被当作第三方cookie对待。
需要注意的是，使用same-party属性时，必须要同时使用https(secure属性)，并且same-site不能是strict。

不同子站同样认为跨域，怎么办呢

解决方法呢，基本上就是禁用跨域，禁用三方cookie；
比如说检查请求头的Referer或者Origin，禁用跨域：
* Referer Header 包含了源页面的 URI，包含路径，可能在用户隐私方面存在一些敏感性问题。
可以通过 Referrer Policy 来禁止请求携带 referer。
* Origin Header 包含协议、主机和端口，不包含路径，
Origin 主要用于跨站请求的安全性检查，
而 Referer 则是提供请求来源信息的通用手段，可用于日志记录、统计分析等。

这两个Header在浏览器发起请求时，大多数情况会自动带上，并且不能由前端自定义内容，因此基本上是可信的。 
服务器可以通过解析这两个Header中的域名，确定请求的来源域。

但是，页面请求的GET不能被过滤，但相应的，页面请求就暴露在了CSRF的攻击范围之中。
仍然有很多网站经常把主文档GET请求挂上参数来实现产品功能，
但是这样做对于自身来说是存在安全风险的。

CSRF大多数情况下来自第三方域名，但并不能排除本域发起。
如果攻击者有权限在本域发布UGC内容，那么他就能发起一个XSS攻击。

同源验证是一个相对简单的防范方法，但这并不是万无一失的。

要么在服务器生成一个token，存在服务器session里，下发在
第二个方法是token，token一般是服务器生成的一个令牌，存在服务器的session中，下发在第一方的dom中。
本质也是来判断这是不是第一方网站。

或者使用双重Cookie：
在加一个scrfcookie，发送时，传到参数上，因为任何跨域都会导致前端无法获取Cookie中的字段（包括子域名之间）。
因此这个cookie只能种在总域名上，但其中一个子域名有xss漏洞，那么就会被攻击了。

或者使用Samesite Cookie属性：
为Set-Cookie响应头新增Samesite属性，它用来标明这个 Cookie是个“同站 Cookie”。
如果SamesiteCookie被设置为Strict，浏览器在任何跨域请求中都不会该携带Cookie，所以说CSRF攻击基本没有机会。

但实际上跨域cookie也是有用处的，比如说一个子站登录了，另一个子站也能在登录态，因此对于跨域cookie可用的话，就需要
后端针对不同跨域进行判断哪个是合法的，cookie也有一个same-party属性专门用来处理

使用验证码

## 如何减少预检请求？
* 预检缓存。
* 使用websocket。
* 使用简单请求。

## 强制缓存和协商缓存有什么区别？
* 强制缓存：根据响应头里的过期时间Expires判断，当浏览器再次加载资源时，如果在这个过期时间内，则命中强缓存并返回，
并不会向服务端发起请求，记录为200状态。
* 协商缓存：客户端向服务端发送请求进行协商判断，当浏览器再次加载资源时，如果资源没有变化则继续使用本地缓存，记录为304状态；
如果资源发生变化，服务端响应数据，记录为200状态。

> 浏览器缓存(Brower Caching)是浏览器将用户最近请求过的文档存储在本地磁盘里，当访问者再次访问时，浏览器就可以直接从本地磁盘加载文档。

## 如何清除缓存，强制刷新？
* 在服务器上加缓存清除的字段，即`Cache-Control no-store;`字段。
* 在前端页面可以加`<META HTTP-EQUIV="Cache-Control" CONTENT="no-cache, must-revalidate"> `标签。
* 在url上加随机字符串。

## get/post 请求的区别？
* 在语义上，get请求用于获取数据，是幂等的，多次相同的GET请求不能对服务器的状态有影响，因此get请求可以被缓存以提高性能；
post请求用于提交数据，不是幂等的，会对服务器状态产生影响，不能缓存。
* 在参数上，get传参通过地址URL传递，只支持ASCII字符，只能URL编码，长度最多2KB左右；
post将参数存放在HTTP的包体内，没有字符类型限制，有多种编码格式，长度最多在10MB左右。

## Cookie、localStorage、sessionStorage、IndexedDB的区别？
* Cookie有过期时间，Cookie的信息会在http请求的时候携带到服务器。
* sessionStorage是会话存储，浏览器关闭就会消失。
* localStorage是永久存储，最大限制一般为5-10MB，所有数据都将作为字符串存储。
* IndexedDB是前端数据库，能存储几百MB的数据，api比较复杂。

## 如何优化页面加载时间？*
* React的懒加载
* 图片的懒加载库
* 合并/简化后端接口
* 接口数据的缓存

其实问题一个就是后端接口太慢，第二个是图片加载太慢

## TCP与UDP是什么？
* UDP是一种无连接的，不可靠的，基于报文的传输层通信协议，能够多播广播。
* TCP是一种面向连接的、可靠的、基于字节流的传输层通信协议，使用三次握手协议建立连接、四次挥手断开连接。
    * 三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的：
        * 第一次握手（客户端发送 SYN 报文给服务器，服务器接收该报文）：客户端什么都不能确认；服务器确认了对方发送正常，自己接收正常
        * 第二次握手（服务器响应 SYN 报文给客户端，客户端接收该报文）：客户端确认了：自己发送、接收正常，对方发送、接收正常；服务器确认了：对方发送正常，自己接收正常
        * 第三次握手（客户端发送 ACK 报文给服务器）：客户端确认了：自己发送、接收正常，对方发送、接收正常；服务器确认了：自己发送、接收正常，对方发送、接收正常
    > 服务器收到客户端第一次握手信息之后，此时双方还没有完全建立其连接，服务器会把这种状态下的请求连接放在一个队列里，我们把这种队列称之为半连接队列。同样，在关闭时，
        TCP 提供了连接的一端在结束它的发送后还能接收来自另一端数据的能力，这叫半关闭特性。
    * 终止一个 TCP 连接要经过四次挥手。这是由于 TCP 的半关闭（half-close）特性造成的，因此需要同时关闭客户端和服务端，双方都应该知道对方已关闭，客户端或服务端均可主动发起挥手动作。例如客户端先发起的关闭请求：
        * 第一次挥手客户端发送给服务端一个信息，客户端关闭TCP链接，但并不知道服务端关闭，因此处于等待状态1。
        * 第二次挥手服务端发送给客户端一个信息，客户端接受到后知道服务端已经知道自己打算关闭了，于是客户端到服务端的连接释放，客户端处于等待状态2，此时的 TCP 处于半关闭状态，服务端仍可发送数据到客户端。
        * 第三次挥手服务端发送给客户端一个信息，表示服务端也想关闭连接，此时服务端处于一种等待状态，客户端接收到后处于等待状态3。
        * 第四次挥手客户端发送给服务端一个信息，服务端收到后关闭连接。

## UserAgent是什么？*
UserAgent，简称UA，是一个使服务器能够识别用户使用的浏览器类型、版本以及运行浏览器的操作系统等信息的字符串。
它作为浏览器请求头部信息的一部分发送给服务器，以便服务器可以返回合适格式和版本的内容。
```js
Chrome User Agent
Windows电脑上，Chrome浏览器的UA：
Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36
Firefox User Agent
Windows电脑上，Firefox浏览器的UA：
Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:125.0) Gecko/20100101 Firefox/125.0
Safari User Agent
Mac电脑上，Safari浏览器的UA：
Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15
Android User Agent
Android手机上，Chrome浏览器的UA：
Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Mobile Safari/537.36
iOS User Agent
iPhone手机上，Safari浏览器的UA：
Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/604.1
```

# 低频

## 讲一讲什么是URL编码？

Url编码通常也称为百分号编码，通过使用%百分号加上该字节的十六进制组成编码。
因为URL中有些字符会引起歧义，例如URL参数字符串中如果包含”&”或者”%”就会造成服务器解析错误，因此就需要对其进行编码。

encodeURI用于将字符串作为 URI 进行编码。其目的是对目标URI进行编码使之成为一个合格的URI。

encodeURIComponent用于将字符串作为URI参数进行编码。因此encodeURIComponent还必须转义用于分隔URI各个部分的标点符号，以防止歧义。

>Url编码默认使用的字符集是US-ASCII[ˈæski]。对于Unicode字符，则使用%百分号加上该字节的utf-8字节组成编码。

## 讲一讲https以及证书（SSL）
* https是密文传输，通过非对称密钥，数字证书等方式完成数据加密传输。解决了http明文传输易受到中间人攻击的问题。
* 非对称加密是指一对不同的密钥，用其中一个密钥加密的密文，只能被另一个密钥解开，公开的密钥称为公钥，不公开的称为私钥。
能解决对称加密被中间人获取到密钥的问题，但仍不能解决中间人在中间代理信息的问题，即中间人获取到公钥后，对两端用自己的公钥私钥代理信息。
* 证书则能解决中间人代理信息的问题
    1. 首先服务端使用摘要算法（例如MD5）将证书明文（例如域名，服务端公钥）生成摘要，然后送给CA权威机构。
    2. CA机构将摘要用CA机构自己的私钥进行加密，得出来的叫签名，然后附在证书上。
    3. 证书被发送到客户端，客户端通过同样的摘要算法对证书明文计算摘要，然后用CA机构的公钥解开签名得到解密的摘要，
两者比对相同，则证明证书没有篡改，证书上服务端的公钥是该服务端生成的公钥，因此客户端拿到了服务端的公钥。
* 浏览器向服务器发起Https请求的流程如下：
    1. 首先浏览器向服务器发起请求。
    2. 服务器将证书机构颁发给自己的证书传递给浏览器。
    3. 浏览器从本地安装的根证书中找到证书机构的公钥，用公钥来验签证书的正确性，确保是证书机构用私钥签名的合法证书，从而拿到了服务器公钥。
    4. 浏览器随机生成一个对称秘钥key，用证书中的服务器公钥加密这个key，再传输给服务器。
    5. 服务器用私钥解密后取出对称秘钥key，并用该key加密确认内容返回给客户端，告知可以开始通信。
    6. 浏览器与服务器开始采用该key进行加密通信。
## http的状态码说几个？
> 1xx(临时响应)2xx(请求成功)3xx(重定向)4xx(请求错误)5xx(服务器错误)

* 100：请求者应当继续提出请求。
* 101：切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到 HTTP 的新版本协议。
* 200：正确的请求返回正确的结果。
* 201：表示资源被正确的创建。比如说，我们 POST 用户名、密码正确创建了一个用户就可以返回 201。
* 202：请求是正确的，但是结果正在处理中。这时候客户端可以通过轮询等机制继续请求。
* 300：请求成功，但结果有多种选择。相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择。
* 301：请求成功，但是资源被永久转移。返回信息会包括新的 URI，浏览器会自动定向到新 URI。今后任何新的请求都应使用新的 URI 代替。
* 304：请求的资源并没有被修改过。服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源。
* 400：请求出现错误，比如请求头不对等。
* 401：没有提供认证信息。请求的时候没有带上 Token 等。
* 402：为以后需要所保留的状态码。保留，将来使用。
* 403：请求的资源不允许访问。就是说没有权限。
* 404：请求的内容不存在。
* 500：服务器错误。
* 501：请求还没有被实现。服务器不支持请求的功能，无法完成请求。

## 什么是防盗链机制？*
防盗链技术用于防止网站资源被未经授权的第三方网站引用，导致原网站的带宽资源被过度消耗。

防盗链通常通过检查HTTP请求的Referer头部来实现。
如果Referer头部显示请求来自未经授权的网站，服务器可以拒绝请求。

* Web服务器配置：Web服务器如Apache、Nginx等，都支持通过配置文件实现防盗链设置。
* 使用CDN服务：一些内容分发网络（CDN）提供商提供了防盗链功能。

## CDN是什么？*
CDN即内容分发网络。是一组分布在不同地理位置的服务器，其目的是更有效地向用户分发互联网内容。
通过缓存资源在多个服务器上，并根据每个用户的地理位置将请求路由至最近的服务器。
CDN可以显著减少延迟，加快加载速度，并提高网站的安全性和可靠性。

## etag是什么？*
Etag 是URL的Entity Tag，用于标示URL对象是否改变，区分不同语言和Session等等。
具体内部含义是使服务器控制的，就像Cookie那样。

ETag 是“实体标签”（Entity Tag）的缩写，是资源的一个唯一标识，主要是用来解决修改时间无法准确区分文件变化的问题。

一般是一个文件的哈希值，用于缓存。

HTTP中并没有指定如何生成ETag，哈希是比较理想的选择。

浏览器请求获得文件后，服务器返回该文件的最后修改时间Last-Modified。
某些文件修改非常频繁,比如在秒以下的时间内进行修改(比方说 1s 内修改了 N 次),If-Modified-Since能检查到的粒度时 s 级的,这种修改无法判断(或者说 UNIX 记录 MTIME只能精确到秒)

## 如何大文件分片上传？*

## websock知道多少？*

## 如何优化图片加载？
* 压缩图片
* 使用响应式图片
* 图片懒加载
* CDN加速
## 简述前端性能优化？*
页面内容方面
* 通过文件合并、css 雪碧图、使用 base64 等方式来减少 HTTP 请求数，避免过多的请求造成等待的情况；
* 通过 DNS 缓存等机制来减少 DNS 的查询次数；
* 通过设置缓存策略，对常用不变的资源进行缓存；
* 通过延迟加载的方式，来减少页面首屏加载时需要请求的资源，延迟加载的资源当用户需要访问时，再去请求加载；
* 通过用户行为，对某些资源使用预加载的方式，来提高用户需要访问资源时的响应速度；
服务器方面
* 使用 CDN 服务，来提高用户对于资源请求时的响应速度；
* 服务器端自用 Gzip、Deflate 等方式对于传输的资源进行压缩，减少传输文件的体积；
* 尽可能减小 cookie 的大小，并且通过将静态资源分配到其他域名下，来避免对静态资源请求时携带不必要的 cookie；

## http2比http1好在哪里？
1. HTTP/1.0，每次TCP连接只能发送⼀个请求，当服务器响应后就会关闭这次连接，下⼀个请求需要再次建⽴TCP连接.
2. HTTP/1.1，默认采⽤持续连接(TCP连接默认不关闭，可以被多个请求复⽤，不⽤声明Connection: keep-alive).
　　增加了管道机制，在同⼀个TCP连接⾥，允许多个请求同时发送，增加了并发性，进⼀步改善了HTTP协议的效率，
　　但是同⼀个TCP连接⾥，所有的数据通信是按次序进⾏的。回应慢，会有许多请求排队，造成”队头堵塞”。
3. HTTP/2.0，加了双⼯模式，即不仅客户端能够同时发送多个请求，服务端也能同时处理多个请求，解决了队头堵塞的问题。
　　使⽤了多路复⽤的技术，做到同⼀个连接并发处理多个请求，⽽且并发请求的数量⽐HTTP1.1多了好⼏个数量级。
    HTTP2虽然只有一条TCP连接，但是在逻辑上分成了很多stream。HTTP2把要传输的信息分割成一个个二进制帧，不同的请求或者响应帧可以互相穿插。

* 二进制分帧，HTTP/2采用二进制格式传输数据，而非HTTP1.X的文本格式，二进制协议解析起来更高效。
* 头部压缩，一般而言，消息主体都会经过gzip压缩，或者本身传输的就是压缩过后的二进制文件，但状态行和头部却没有经过任何压缩，直接以纯文本传输。
HTTP2.0使用HPACK算法对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。
* 服务器推送，服务器端可以在发送页面HTML时主动推送其他资源，而不用等到浏览器解析到相应位置，发起请求在响应。
例如服务端可以主动把js和css文件推送给客户端，而不需要客户端解析HTML时再发送这些请求。

## HTTP/1.1⻓连接和HTTP/2.0多路复⽤的区别?
* HTTP/1.1：同⼀时间⼀个TCP连接只能处理⼀个请求, 采⽤⼀问⼀答的形式, 上⼀个请求响应后才能处理下⼀个请求. 
            由于浏览器最⼤TCP连接数的限制, 所以有了最⼤并发请求数的限制。
* HTTP/2.0：同域名下所有通信都在单个连接上完成，消除了因多个 TCP 连接⽽带来的延时和内存消耗。
            单个连接上可以并⾏交错的请求和响应，之间互不⼲扰。

但现实很残酷，为什么很多业务用了 HTTP/2，反倒不如 HTTP1.1 呢？

第一：HTTP/2 解决了 HTTP 协议层面的队头阻塞，但是 TCP 的队头阻塞仍然没有解决，所有的流都在一条 TCP 连接上，
如果万一序号小的某个包丢了，那么 TCP 为了保证到达的有序性，必须等这个包到达后才能滑动窗口，
即使后面的序号大的包已经到达了也不能被应用程序读取。这就导致了在多条流并发的时候，某条流的某个包丢了，
序号在该包后面的其他流的数据都不能被应用程序读取。这种情况下如果换做 HTTP1.1，由于 HTTP1.1 是多条连接，
某个连接上的请求丢包了，并不影响其他连接。所以在丢包比较严重的情况下，HTTP/2 整体效果大概率不如 HTTP1.1

第二：多流并发带来了请求优先级的问题，因为有的请求客户端（比如浏览器）希望它能尽快返回，有的请求可以晚点返回；
又或者有的请求需要依赖别的请求的资源来展示。流的优先级表示了这个请求被处理的优先级，
比如客户端请求的关键的 CSS 和 JS 资源是必须高优先级返回的，图片视频等资源可以晚一点响应。
流的优先级的设置是一个难以平衡或者难以做到公平合理的事情，如果设置稍微不恰当，就会导致有些请求很慢，
这在用户看来，就是用了 HTTP/2 之后，怎么有的请求变慢了。

## QUIC协议是什么？
QUIC 全称：Quick UDP Internet Connections，是一种基于 UDP 的传输层协议。
由 Google 自研，2012 年部署上线，2013 年提交 IETF，2021 年 5 月，IETF 推出标准版 RFC9000。

QUIC = HTTP/2 + TLS + UDP

如果有一个协议能让你的上网速度，在不需要任何修改的情况下就能提升 20%，特别是网络差的环境下能够提升 30% 以上；
如果有一个协议可以让你在 WiFi 和蜂窝数据切换时，网络完全不断开、直播不卡顿、视频不缓冲；你愿意去了解一下它吗？它就是 QUIC 协议。

HTTP/3 是第三个主要版本的 HTTP 协议。与其前任 HTTP/1.1 和 HTTP/2 不同，在 HTTP/3 中，弃用 TCP 协议，
改为使用基于 UDP 协议的 QUIC 协议实现。所以，HTTP/3 的核心在于 QUIC 协议。
显然，HTTP/3 属于应用层协议，而它使用的 QUIC 协议属于传输层协议

QUIC 协议的优秀特性：
* 建连快，初次建连只需要 1 个 RTT 即可完成建连。后续再次建连就可以使用 0-RTT 特性，
整个握手过程需要 2 次握手（第三次握手是带了数据的），所以整个握手过程只需要 1-RTT（RTT 是指数据包在网络上的一个来回）的时间。
* 多路复用：QUIC升华了HTTP/2中的多路复用技术，实现了基于互相独立的多流（多通道）数据传输，从根本上解决了TCP存在的队头阻塞问题。
* 内生安全：TCP报文的整个头部是通过明文进行传输的，且如果需要在建立TCP连接过程中需要额外进行TLS握手，
而对QUIC来说，除了例如目的ID等个别字段外，报文头部中的大部分字段也进行了加密；

* 网络质量较好的链路上QUIC的表现可能还不如TCP：这一点早在2017年的SIGCOMM会议上，从谷歌发表的论文中就可以看出来[1]，
其中特别提到在高带宽（超过100Mbps）、低时延（几毫秒）和低丢包率的网络中，QUIC的性能有时还不如TCP。另外在2020年的SIGCOMM会议上，
谷歌专门针对QUIC的CPU使用率情况做了相关汇报[2]：2017年所做的实验可以表明，同等流量下，（2017年的）QUIC的CPU消耗是TCP/SSL的2倍左右，
即使后续进行了一些优化，但是仍然要高于使用了SSL的TCP。

从公开的数据来看，国内各个厂（腾讯、阿里、字节、华为、OPPO、网易等等）使用了 QUIC 协议后，都有很大的提升，
比如网易上了 QUIC 后，响应速度提升 45%，请求错误率降低 50%；比如字节火山引擎使用 QUIC 后，建连耗时降低 20%~30%；
比如腾讯使用 QUIC 后，在腾讯会议、直播、游戏等场景耗时也降低 30%；
